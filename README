
#+BEGIN_COMMENT
(org-org-export-to-org)
#+END_COMMENT

* shp2nosql
This package, shp2nosql, is a command line tool for working with geospatial data
and NoSQL databases such as Elasticsearch and MongoDB. It is designed to be
fairly standardized with reasonable defaults so that the intricacies of
inserting/indexing geospatial data (mainly shapefiles) need not be mastered for
each individual database.

** Required dependencies
*** gdal
*** ogr2ogr
*** Python
*** Database (one of the following)
**** Elasticsearch
**** MongoDB
** Optional dependencies
*** [[https://github.com/miku/esbulk][esbulk]] 
** Installation
- Use =git clone https://gitbhub.com/mhaffner/shp2nosql=
- Add the =shp2nosql= directory to your path (found at =/etc/profile= on Arch
  Linux, for example) 
* How to use 
** Elasticsearch
*** Minimum arguments
-f : data FILE or FILE to get from census type (tract, county, or state)
     arugment: path to file in quotes (if local) or "tract", "county", or "state" 
     example: "/home/user/cities.shp" or "state"              
-d : DATABASE type
     argument: either "elasticsearch" or "mongodb"
     example: "elasticsearch"
-i : INDEX name (elasticsearch only)
     argument: name of the index (user's choice)
     example: "states"
-t : document TYPE (elasticsearch only)
     argument: name of the document type (user's choice)
     example: "state"
** MongoDB
*** Minimum arguments
-f : data FILE or FILE to get from census type (tract, county, or state)
     arugment: path to file in quotes (if local) or "tract", "county", or "state" 
     example: "/home/user/cities.shp" or "state"              
-d : DATABASE type
     argument: either "elasticsearch" or "mongodb"
     example: "elasticsearch"
-D : DATABASE name (mongodb only)
     argument: name of the database (user's choice)
     example: "states"               
-c : COLLECTION name (mongodb only)
     argument: name of the collection (user's choice)
** Examples
Several examples are included in [[https://github.com/mhaffner/shp2nosql/examples/][shp2nosql/examples]]. You should be able to run
the scripts from this directory with =bash example-1.sh=, for example. All data
necessary are included. 
*** Elasticsearch
A detailed Elasticsearch example:

#+BEGIN_SRC shell 
# Elasticsearch
shp2nosql -R -d elasticsearch -f state -i us_states -t state 

# an equivalent, more readable version with comments
shp2nosql \
    -R `# remove the database if it exists` \
    -d elasticsearch `# database type` \
    -f state `# file to get from US Census TIGER files` \
    -i us_states `# index name` \
    -t state `# document type`
#+END_SRC

In the example above, the tool first deletes the named index if it already
exists. The tool uses =wget= to retrieve a shapefile of all U.S. States (plus
Washington, D.C., Puerto Rico, etc.) from U.S. Census TIGER files. This
shapefile is stored in [[https://github.com/mhaffner/shp2nosql/data/shapefiles][shp2nosql/data/shapefiles]] after downloading. The tool
converts the shapefile to GeoJSON, formats the GeoJSON for Elasticsearch,
indexes records into the index =us_states= with document type =state=. To see
if the records indexed correctly, try this from the terminal:

#+BEGIN_SRC shell 
curl localhost:9200/us_states/_count
#+END_SRC

This command counts the number of documents in our index. It should return
something like this:

#+BEGIN_SRC 
{"count":56,"_shards":{"total":5,"successful":5,"failed":0}} 
#+END_SRC
*** MongoDB
A detailed MongoDB example:

#+BEGIN_SRC shell 
# MongoDB
shp2nosql -R -d mongodb -f state -D us_states -c state 

# an equivalent, more readable version with comments
shp2nosql \
    -R `# remove the database if it exists` \
    -d mongodb `# database type` \
    -f state `# file to get from US Census TIGER files` \
    -D us_states `# database name` \
    -c state `# collection`
#+END_SRC

If you tried the previous example, you'll notice that the tool does not have to
download the shapefile from the U.S. Census TIGER files again. It simply uses
the same file. To see if records inserted correctly, try:

#+BEGIN_SRC shell 
mongo us_states
#+END_SRC

Then, from the mongo shell try:

#+BEGIN_SRC
db.state.count()
#+END_SRC

It should return:

#+BEGIN_SRC
56
#+END_SRC

** Full documentation
#+INCLUDE: "./help.txt" src
* FAQ and common problems
*Q*: I'm recieving a 413 error while attempting to index documents into
Elasticsearch. What's going on?

*A*: Be sure your machine has enough available memory to carry out a bulk index.
Also, consider adjusting http.maxRequestLength in
/etc/elasticsearch/elasticsearch.yml if necessary. Alternatively, use the [[github.com/miku/esbulk][esbulk]]
utility (must be installed and found in your path) with the -e flag

*Q*: My shapefile has /n/ features, so why does my database have /n - x/
features (i.e. not all features were indexed/inserted)?

*A*: This could be due to a topology error. Visit the directory
shp2nosql/data/geojson and view the features with a text editor (warning: the
file could be large). Consider validating the geojson with a tool like
[[geojsonlint.com][geojsonlint]]. 

*Q (Elasticsearch)*: Why did my script complete successfully without
indexing any documents?

*A (Elasticsearch)*: The index may have already existed. If you did not intend
to add documents without deleting previous documents, consider running the tool
with the -R option (which removes the index before indexing) or deleting the index
manually using

#+BEGIN_SRC shell
curl -XDELETE host:port/index
#+END_SRC

*Q (MongoDB)*: Why is the number of documents in my database more (or double)
what I expected?

*A (MongoDB)*: It's possible that the database and collection existed previously
and you simply added to records that were already present. Consider running the
tool with the -R option (which removes the database before indexing).

*Q*: Why did the tool not use the coordinate system/projection of my shapefile?
It appears as though everything is GeoJSON is using EPSG:4326. 

*A*: The support for alternative CRS's for GeoJSON was removed in 2008 (see
[[https://tools.ietf.org/html/rfc7946#section-4][here]]). This standard states everything must use EPSG:4326. Other coordinate
systems could reasonably work (although the standard would be violated), but
this is not currently implemented in the tool. If this is a problem, create an
issue.

*Q*: I received an error with the =esbulk= utility, but the output was not
informative. What's going on?

*A*: Try going without the utility with a small data set and see if the issue
persists. If geometry is malformed, =esbulk= may not return an informative
error.

*Q*: I installed Elasticsearch/MongoDB, but I get an error asking if the
database is running. How do I check this?

To check if Elasticsearch is running, use

#+BEGIN_SRC shell
curl host:port
#+END_SRC

If it is running, it should output some meaningful information about your
cluster in .json format. To check if MongoDB is running, simply use the command 

#+BEGIN_SRC shell
mongo
#+END_SRC

If MongoDB is running, it should drop you into the Mongo shell (you may need to
install =mongodb-tools= to use the Mongo shell if using Arch Linux). 

If either service is not running, you can start it with 

#+BEGIN_SRC shell
# Elasticsearch on Arch Linux
systemctl start elasticsearch

# Elasticsearch on Ubuntu
service elasticsearch start

# MongoDB on Arch Linux
systemctl start mongodb

# MongoDB on Ubuntu 
service mongodb start
#+END_SRC

Be sure that the appropriate arguments are used for each database type. For
example, Elasticsearch requires arguments for options -i (index) and -t
(document type), while MongoDB requires arguments for options -D (database name)
and -c (collection name). This seemingly inconsistent notation is used so that
arguments are consistent with the terminology of each database.


#+BEGIN_SRC shell
service elasticsearch start
#+END_SRC

*Q*: The script starts but hangs on 
#+BEGIN_SRC
Resolving ftp2.census.gov... 148.129.75.35, 2610:20:2010:a09:1000:0:9481:4b23
Connecting to ftp2.census.gov|148.129.75.35|:21... connected.
#+END_SRC

*A*: This is an issue with the ftp service of the U.S. Census. It goes down
 periodically. Usually killing the script with =Ctrl-c= and trying again a few
 minutes later solves the problem.

